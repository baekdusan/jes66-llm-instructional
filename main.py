import streamlit as st
from openai import OpenAI
from utils import render_with_latex
from prompts import for_system_prompt, system_prompt
from sidebar import render_sidebar
from database import Database
import os
import json


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

# ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìœ¼ë©´ Falseë¡œ ì´ˆê¸°í™”
if "system_prompt_created" not in st.session_state:
    st.session_state.system_prompt_created = False

# í˜„ì¬ ëŒ€í™” ì„¸ì…˜ IDê°€ ì—†ìœ¼ë©´ Noneë¡œ ì´ˆê¸°í™”
if "current_conversation_id" not in st.session_state:
    st.session_state.current_conversation_id = None

# API í‚¤ ìœ íš¨ì„± ê²€ì¦ ìƒíƒœê°€ ì—†ìœ¼ë©´ Falseë¡œ ì´ˆê¸°í™”
if "api_key_valid" not in st.session_state:
    st.session_state.api_key_valid = False

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
db = Database()

# Streamlit ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="Dusan Baek", page_icon="ğŸ§‘â€ğŸ«")
st.title("Chatbot service by Instructional Design Theory")

# ì‚¬ì´ë“œë°” ë Œë”ë§
render_sidebar()

# API í‚¤ ìœ íš¨ì„± ê²€ì¦ ìƒíƒœ í™•ì¸
if not st.session_state.api_key_valid:
    st.warning("OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ìœ íš¨í•œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()  # ì—¬ê¸°ì„œ ì‹¤í–‰ì„ ì¤‘ë‹¨í•˜ì—¬ ì±„íŒ… ê¸°ëŠ¥ ì œí•œ

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
api_key = st.session_state.get("openai_api_key", st.secrets.get("openai", {}).get("api_key", ""))
client = OpenAI(api_key=api_key)

# ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥ (ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
if st.session_state.messages and st.session_state.system_prompt_created:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

if user_input:
    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ì¸ ê²½ìš° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    if not st.session_state.messages:
        # ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ìƒì„±
        if not st.session_state.current_conversation_id:
            conversation_title = user_input[:50] + "..." if len(user_input) > 50 else user_input
            st.session_state.current_conversation_id = db.create_conversation(conversation_title)
        
        with st.spinner("êµìˆ˜ ì„¤ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ..."):
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = for_system_prompt.format(user_input=user_input)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=2000
            )
            
            try:
                # JSON ì‘ë‹µ íŒŒì‹±
                content = response.choices[0].message.content
                result = json.loads(content)
                
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                system_prompt_content = system_prompt.format(
                    analysis_content=result["analysis_content"],
                    design_content=result["design_content"]
                )
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                if st.session_state.current_conversation_id:
                    db.save_message(st.session_state.current_conversation_id, "system", system_prompt_content)
                
                st.session_state.system_prompt_created = True
                st.session_state.messages.append({"role": "system", "content": system_prompt_content})
                
            except json.JSONDecodeError:
                st.error("í”„ë ˆì„ì›Œí¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                
                # ì¬ì‹œë„ ë²„íŠ¼ ì¶”ê°€
                col1, col2 = st.columns([1, 4])
                with col1:
                    if st.button("ë‹¤ì‹œ ì‹œë„", key="retry_button"):
                        st.session_state.messages = []  # ë©”ì‹œì§€ ì´ˆê¸°í™”
                        st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                with col2:
                    st.info("ì¬ì‹œë„ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

            # ì‚¬ìš©ìì˜ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": user_input})
            db.save_message(st.session_state.current_conversation_id, "user", user_input)

            # AI ì‘ë‹µ ì¶œë ¥ ì˜ì—­
            with st.chat_message("assistant"):
                stream_placeholder = st.empty()
                full_response = ""

                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=st.session_state.messages,
                    stream=True
                )

                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°›ê¸°
                for chunk in response:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        stream_placeholder.markdown(full_response + "â–Œ")

                # ìŠ¤íŠ¸ë¦¬ë° ëë‚œ í›„ ìˆ˜ì‹ í¬í•¨í•´ì„œ ë‹¤ì‹œ ë Œë”ë§
                stream_placeholder.empty()
                render_with_latex(full_response)

                # ì‘ë‹µ ì €ì¥
                st.session_state.messages.append(
                    {"role": "assistant", "content": full_response}
                )
                db.save_message(st.session_state.current_conversation_id, "assistant", full_response)
    else:
        # ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš° ì¼ë°˜ì ì¸ ëŒ€í™” ì§„í–‰
        st.session_state.messages.append({"role": "user", "content": user_input})
        db.save_message(st.session_state.current_conversation_id, "user", user_input)
        
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            stream_placeholder = st.empty()
            full_response = ""

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=st.session_state.messages,
                stream=True
            )

            for chunk in response:
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    stream_placeholder.markdown(full_response + "â–Œ")

            stream_placeholder.empty()
            render_with_latex(full_response)

            # ì‘ë‹µ ì €ì¥
            st.session_state.messages.append(
                {"role": "assistant", "content": full_response}
            )
            db.save_message(st.session_state.current_conversation_id, "assistant", full_response)

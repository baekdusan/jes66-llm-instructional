import streamlit as st
from openai import OpenAI
from utils import render_with_latex
from prompts import (
    for_system_prompt_with_reference,
    for_system_prompt_without_reference,
    system_prompt,
    COMMON_INSTRUCTIONS,
    feedback_analysis_prompt
)
from sidebar import render_sidebar
from database import Database
import os
import json
import PyPDF2

def read_pdf_content(pdf_path):
    """PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    content = ""
    with open(pdf_path, 'rb') as file:
        pdf_reader = PyPDF2.PdfReader(file)
        for page in pdf_reader.pages:
            content += page.extract_text()
    return content

# PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
ADDIE_PDF_PATH = "ADDIE_Model_All_Stages_Detailed_Concepts_with_References.pdf"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

# ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìœ¼ë©´ Falseë¡œ ì´ˆê¸°í™”
if "system_prompt_created" not in st.session_state:
    st.session_state.system_prompt_created = False

# í˜„ì¬ ëŒ€í™” ì„¸ì…˜ IDê°€ ì—†ìœ¼ë©´ Noneë¡œ ì´ˆê¸°í™”
if "current_conversation_id" not in st.session_state:
    st.session_state.current_conversation_id = None

# API í‚¤ ìœ íš¨ì„± ê²€ì¦ ìƒíƒœê°€ ì—†ìœ¼ë©´ Falseë¡œ ì´ˆê¸°í™”
if "api_key_valid" not in st.session_state:
    st.session_state.api_key_valid = False

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
db = Database()

# ADDIE ë¬¸ì„œê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ìœ¼ë©´ ì €ì¥ ì‹œë„
if not db.get_addie_document():
    try:
        if os.path.exists(ADDIE_PDF_PATH):
            addie_content = read_pdf_content(ADDIE_PDF_PATH)
            db.save_addie_document(addie_content)
    except Exception as e:
        st.info("ADDIE ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLMì˜ ì¶”ë¡ ì— ê¸°ë°˜í•˜ì—¬ ì§„í–‰í•©ë‹ˆë‹¤.")

# Streamlit ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="Dusan Baek", page_icon="ğŸ§‘â€ğŸ«")
st.title("Chatbot service by Instructional Design Theory")

# ì‚¬ì´ë“œë°” ë Œë”ë§
render_sidebar()

# API í‚¤ ìœ íš¨ì„± ê²€ì¦ ìƒíƒœ í™•ì¸
if not st.session_state.api_key_valid:
    st.warning("OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ìœ íš¨í•œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()  # ì—¬ê¸°ì„œ ì‹¤í–‰ì„ ì¤‘ë‹¨í•˜ì—¬ ì±„íŒ… ê¸°ëŠ¥ ì œí•œ

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
api_key = st.session_state.get("openai_api_key", st.secrets.get("openai", {}).get("api_key", ""))
client = OpenAI(api_key=api_key)

# ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥ (ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
if st.session_state.messages and st.session_state.system_prompt_created:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            if msg["role"] == "assistant":
                render_with_latex(msg["content"])
            else:
                st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

def analyze_feedback(current_context, user_feedback):
    """ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ í•™ìŠµ ìƒíƒœë¥¼ í‰ê°€í•©ë‹ˆë‹¤."""
    try:
        # í”¼ë“œë°± ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = feedback_analysis_prompt.format(
            current_context=current_context,
            user_feedback=user_feedback
        )
        
        # í”¼ë“œë°± ë¶„ì„ ìš”ì²­
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1000
        )
        
        # JSON ì‘ë‹µ íŒŒì‹±
        content = response.choices[0].message.content
        content = content.replace("```json", "").replace("```", "").strip()
        content = " ".join(line.strip() for line in content.splitlines())
        result = json.loads(content)
        
        return result
        
    except Exception as e:
        st.error(f"í”¼ë“œë°± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return {"status": "ì§„í–‰", "reason": "ì˜¤ë¥˜ ë°œìƒ", "feedback_type": "ê¸°íƒ€"}

if user_input:
    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ì¸ ê²½ìš° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    if not st.session_state.messages:
        # ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ìƒì„±
        if not st.session_state.current_conversation_id:
            conversation_title = user_input[:50] + "..." if len(user_input) > 50 else user_input
            st.session_state.current_conversation_id = db.create_conversation(conversation_title)
        
        with st.spinner("êµìˆ˜ ì„¤ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ..."):
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ADDIE ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
            addie_reference_content = db.get_addie_document()
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            if addie_reference_content:
                prompt = for_system_prompt_with_reference.format(
                    user_input=user_input,
                    addie_reference_content=addie_reference_content,
                    common_instructions=COMMON_INSTRUCTIONS
                )
                # st.write("ì°¸ì¡° ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±")
            else:
                prompt = for_system_prompt_without_reference.format(
                    user_input=user_input,
                    common_instructions=COMMON_INSTRUCTIONS
                )
                # st.write("ì°¸ì¡° ë¬¸ì„œ ì—†ì´ í”„ë¡¬í”„íŠ¸ ìƒì„±")
            
            # st.write("ìƒì„±ëœ í”„ë¡¬í”„íŠ¸:", prompt)
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=2000
            )
            
            try:
                # JSON ì‘ë‹µ íŒŒì‹±
                content = response.choices[0].message.content
                # st.write("ëª¨ë¸ ì‘ë‹µ:", content)
                
                # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ í‘œì‹œ ì œê±°
                content = content.replace("```json", "").replace("```", "").strip()
                
                # JSON ì •ê·œí™” (ì—¬ëŸ¬ ì¤„ì„ í•œ ì¤„ë¡œ)
                content = " ".join(line.strip() for line in content.splitlines())
                
                result = json.loads(content)
                st.write("íŒŒì‹±ëœ JSON:", result)
                
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                system_prompt_content = system_prompt.format(
                    analysis_content=result["analysis_content"],
                    design_content=result["design_content"]
                )
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                if st.session_state.current_conversation_id:
                    db.save_message(st.session_state.current_conversation_id, "system", system_prompt_content)
                
                st.session_state.system_prompt_created = True
                st.session_state.messages.append({"role": "system", "content": system_prompt_content})
                
            except (json.JSONDecodeError, KeyError) as e:
                st.error(f"í”„ë ˆì„ì›Œí¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.info("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                
                # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.messages = []
                st.session_state.system_prompt_created = False
                st.session_state.current_conversation_id = None
                
                # ì¬ì‹œë„ ë²„íŠ¼
                if st.button("ë‹¤ì‹œ ì‹œë„", key="retry_button"):
                    st.rerun()
                
                st.stop()  # ì—¬ê¸°ì„œ ì‹¤í–‰ ì¤‘ë‹¨

            # ì‚¬ìš©ìì˜ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": user_input})
            db.save_message(st.session_state.current_conversation_id, "user", user_input)

            # AI ì‘ë‹µ ì¶œë ¥ ì˜ì—­
            with st.chat_message("assistant"):
                stream_placeholder = st.empty()
                full_response = ""

                try:
                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=st.session_state.messages,
                        stream=True
                    )

                    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°›ê¸°
                    for chunk in response:
                        if chunk.choices and chunk.choices[0].delta.content:
                            content = chunk.choices[0].delta.content
                            full_response += content
                            stream_placeholder.markdown(full_response + "â–Œ")

                    # ìŠ¤íŠ¸ë¦¬ë° ëë‚œ í›„ ìˆ˜ì‹ í¬í•¨í•´ì„œ ë‹¤ì‹œ ë Œë”ë§
                    stream_placeholder.empty()
                    render_with_latex(full_response)

                    # ì‘ë‹µ ì €ì¥
                    st.session_state.messages.append(
                        {"role": "assistant", "content": full_response}
                    )
                    db.save_message(st.session_state.current_conversation_id, "assistant", full_response)
                    
                except Exception as e:
                    st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    st.stop()
    else:
        # ë‘ ë²ˆì§¸ ë©”ì‹œì§€ë¶€í„°ëŠ” í”¼ë“œë°± ë¶„ì„
        # ì´ì „ ë©”ì‹œì§€ê°€ 3ê°œ ë¯¸ë§Œì¸ ê²½ìš°ëŠ” ìˆëŠ” ë§Œí¼ë§Œ ì‚¬ìš©
        context_messages = st.session_state.messages[-3:] if len(st.session_state.messages) >= 3 else st.session_state.messages
        current_context = "\n".join([msg["content"] for msg in context_messages])
        
        feedback_analysis = analyze_feedback(current_context, user_input)
        
        # í”¼ë“œë°±ì´ "í‰ê°€" ìƒíƒœì¸ ê²½ìš° ìƒˆë¡œìš´ ë¶„ì„ê³¼ ì„¤ê³„ ì¶”ê°€
        print(feedback_analysis["status"], feedback_analysis["suggested_adjustment"])
        if feedback_analysis["status"] == "í‰ê°€" and "suggested_adjustment" in feedback_analysis:
            # ìƒˆë¡œìš´ ë¶„ì„ê³¼ ì„¤ê³„ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€ (ì‚¬ìš©ìì—ê²ŒëŠ” ë³´ì´ì§€ ì•ŠìŒ)
            st.session_state.messages.append({
                "role": "system",
                "content": feedback_analysis["suggested_adjustment"]
            })
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input})
        db.save_message(st.session_state.current_conversation_id, "user", user_input)
        
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            stream_placeholder = st.empty()
            full_response = ""

            try:
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=st.session_state.messages,
                    stream=True
                )

                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°›ê¸°
                for chunk in response:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        stream_placeholder.markdown(full_response + "â–Œ")

                # ìŠ¤íŠ¸ë¦¬ë° ëë‚œ í›„ ìˆ˜ì‹ í¬í•¨í•´ì„œ ë‹¤ì‹œ ë Œë”ë§
                stream_placeholder.empty()
                render_with_latex(full_response)

                # ì‘ë‹µ ì €ì¥
                st.session_state.messages.append(
                    {"role": "assistant", "content": full_response}
                )
                db.save_message(st.session_state.current_conversation_id, "assistant", full_response)
                
            except Exception as e:
                st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.info("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                st.stop()
